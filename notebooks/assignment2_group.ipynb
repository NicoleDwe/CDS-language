{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String processing with Python\n",
    "\n",
    "Using a text corpus found on the cds-language GitHub repo or a corpus of your own found on a site such as Kaggle, write a Python script which calculates collocates for a specific keyword.\n",
    "\n",
    "The script should take a directory of text files, a keyword, and a window size (number of words) as input parameters, and an output file called out/{filename}.csv\n",
    "These parameters can be defined in the script itself\n",
    "Find out how often each word collocates with the target across the corpus\n",
    "Use this to calculate mutual information between the target word and all collocates across the corpus\n",
    "Save result as a single file consisting of four columns: collocate, raw_frequency, MI\n",
    "\n",
    "\n",
    "BONUS CHALLENGE: Use argparse to take inputs from the command line as parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Importing libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "sys.path.append(os.path.join(\"..\")) # enabling communication with home directory\n",
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "import csv \n",
    "import re\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Defining tokenizer function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(input_string):\n",
    "    # Split at all characters except for letters (both lowercase and uppercase) and apostrophes\n",
    "    tokenizer = re.compile(r\"[^a-zA-Z']+\") \n",
    "    # Tokenize\n",
    "    token_list = tokenizer.split(input_string) # return a token list by splitting the input string using the compiling pattern\n",
    "    # Return list of tokens\n",
    "    token_list.remove(\"\")\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he', \"wasn't\", 'happy', 'but', 'would', 'never', 'forget', 'test', 'test']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(\"he wasn't happy, but would never forget. test test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Defining collocate function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collocates(path, keyword, window_size):\n",
    "    \n",
    "    token_list_all = []\n",
    "    collocates_list = []\n",
    "    data = pd.DataFrame(columns=[\"keyword\", \"collocate\", \"raw_frequency\", \"MI\"])\n",
    "    u = 0\n",
    "    \n",
    "    for filename in Path(path).glob(\"*.txt\"):\n",
    "        with open (filename, \"r\", encoding = \"utf-8\") as file:\n",
    "            text = file.read()\n",
    "            token_list = tokenize(text.lower())\n",
    "            token_list_all.extend(token_list)\n",
    "            indices = [index for index, x in enumerate(token_list) if x == keyword]\n",
    "            u = u + len(indices)\n",
    "            \n",
    "#def collocates_list(index_list, token_list, window_size):\n",
    "            for index in indices:\n",
    "                window_start = max(0, index - window_size)\n",
    "                window_end = index + window_size\n",
    "                keyword_string = token_list[window_start : window_end + 1]\n",
    "                collocates_list.extend(keyword_string)\n",
    "                collocates_list.remove(keyword)\n",
    "                \n",
    "    # Now we are going to calculate collocate frequency         \n",
    "    unique_collocates = set(collocates_list)\n",
    "    for collocate in unique_collocates:\n",
    "        v = token_list_all.count(collocate)\n",
    "        raw_frequency = v/len(token_list_all)\n",
    "        O11 = collocates_list.count(collocate)\n",
    "        O12 = u - O11\n",
    "        O21 = v - O11\n",
    "        R1 = O11 + O12\n",
    "        C1 = O11 + O21\n",
    "        N = len(token_list_all)\n",
    "        E11 = R1*C1/N\n",
    "        MI = np.log(O11/E11)\n",
    "        data = data.append({\"keyword\": keyword, \n",
    "                     \"collocate\": collocate, \n",
    "                     \"raw_frequency\": raw_frequency,\n",
    "                     \"MI\": MI}, ignore_index = True)\n",
    "        \n",
    "    data = data.sort_values(\"MI\", ascending = False)    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O11 = u & v = in lines from KWIC, how often do we have the collocate in it  \n",
    "O12 = u & !v = total number of u’s - O11 <br>\n",
    "O21 = !u & v = total number of v’s - O11 <br>\n",
    "R1 = O11 + O12 <br>\n",
    "C1 = O11 + O21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"..\", \"data\", \"100_english_novels\", \"test_corpus\")\n",
    "collocates_df = collocates(path, \"he\", 2)\n",
    "collocates_df.to_csv(\"Collocates.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>collocate</th>\n",
       "      <th>raw_frequency</th>\n",
       "      <th>MI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4358</th>\n",
       "      <td>he</td>\n",
       "      <td>prospered</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>5.209240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>he</td>\n",
       "      <td>hope's</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>5.209240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>he</td>\n",
       "      <td>lisped</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>5.209240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>he</td>\n",
       "      <td>relents</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>5.209240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>he</td>\n",
       "      <td>adores</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>5.209240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>he</td>\n",
       "      <td>she</td>\n",
       "      <td>0.008047</td>\n",
       "      <td>-0.780724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2423</th>\n",
       "      <td>he</td>\n",
       "      <td>sweet</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>-0.782225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>he</td>\n",
       "      <td>are</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>-0.784722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3068</th>\n",
       "      <td>he</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>-0.840494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3372</th>\n",
       "      <td>he</td>\n",
       "      <td>among</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>-1.160661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4542 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     keyword  collocate  raw_frequency        MI\n",
       "4358      he  prospered       0.000001  5.209240\n",
       "3228      he     hope's       0.000001  5.209240\n",
       "719       he     lisped       0.000001  5.209240\n",
       "1357      he    relents       0.000001  5.209240\n",
       "672       he     adores       0.000001  5.209240\n",
       "...      ...        ...            ...       ...\n",
       "1938      he        she       0.008047 -0.780724\n",
       "2423      he      sweet       0.000269 -0.782225\n",
       "1105      he        are       0.002154 -0.784722\n",
       "3068      he      clear       0.000285 -0.840494\n",
       "3372      he      among       0.000392 -1.160661\n",
       "\n",
       "[4542 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collocates_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang101",
   "language": "python",
   "name": "lang101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
